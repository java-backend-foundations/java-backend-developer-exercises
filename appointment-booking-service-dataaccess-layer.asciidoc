:toc: macro
:sectnums:
:sectnumlevels: 3

= Appointment Booking System - Data Access Layer

In this chapter we are going to create a database schema with initial data.
Then we will map it into entities model and provide operations for management of the entities.

toc::[]

== Create your component

After you have completed your own link:appointment-booking-service-setup.asciidoc[Appointment Booking System Setup], we are going to create our first app component.

Going back to our example application, link:appointment-booking-system-specification.asciidoc[Appointment Booking System], we need to provide basic functionalities:

- Adding a new `Treatment` associated with a `Specialist`
- Retrieving a list of available `Treatments`, optionaly filtered by `Specialist` or `Treatment` name
- Retrieving the details of a `Treatment` - gathering information from `Treatment` and connected `Specialist`
- Choosing a `Treatment` as a `Client` and creating an `Appointment` for a given date and hour
- Validation of `Appointment` date conflict by checking if the date does not colide with other Appointments assigned to a `Specialist` (there can`t be two `Appointments` created for the same `Specialist` at the same time)
- Possibility for a `Client` to check their own appointments
- Cancelling the `Appointment` by the `Client`
- Marking the `Appointment` as completed by the `Specialist`
- Optional: retrieving the history of visits for a `Client` and a `Specialist`

To accomplish that we are going to work with five entities: _UserEntity_, _ClientEntity_, _SpecialistEntity_, _TreatmentEntity_ and _AppointmentEntity_.

image::images/dataaccess/dataaccess_entities_uml.png[width="1000", link="images/dataaccess/dataaccess_entities_uml.png"]

Each of the entities will have an id generated with a sequence, version which specifies version number of the entity, created and lastUpdated Instant fields, which will inform, when the entity was created and last changed.

The _UserEntity_ will be defined by email, passwordHash, firstName and lastName. The email will always be unique.

The _ClientEntity_ will have a _UserEntity_, which it's connected to. It will also have a collection of appointments (_AppointmentEntities_).

The _SpecialistEntity_ will be defined by a specialization (as an enum of type _Specialization_, with a converter). It will have a _UserEntity_, which it's connected to and hold a list of treatments, a certain specialist provides (_TreatmentEntities_).

The _TreatmentEntity_ will be defined by name, description and duration of the treatment (in minutes). It will have a SpecialistEntity, which describes, which specialist provides given treatment.

The _AppointmentEntity_ will be defined by dateTime and status (as an enum of type _AppointmentStatus_). It will have a _ClientEntity_ and _TreatmentEntity_, with which it's connected.

* *One-to-One Relationships*
** A *User* has a *one-to-one* relationship with *Client*.
** A *User* has a *one-to-one* relationship with *Specialist*. +
Each user can either be a *Client* or a *Specialist*, but not both.

* *One-to-Many Relationships*
** A *Specialist* has a *one-to-many* relationship with *Treatment*. +
A specialist can provide multiple treatments, but each treatment is provided by only one specialist.
** A *Client* has a *one-to-many* relationship with *Appointment*. +
A client can book multiple appointments, but each appointment belongs to only one client.
** A *Treatment* has a *one-to-many* relationship with *Appointment*. +
A treatment can be booked in multiple appointments, but each appointment refers to only one treatment.

* *Many-to-One Relationships*
** An *Appointment* has a *many-to-one* relationship with *Client*. +
Multiple appointments can belong to the same client.
** An *Appointment* has a *many-to-one* relationship with *Treatment*. +
Multiple appointments can be scheduled for the same treatment.
    
Only relationships Client - Appointment, and Specialist - Treatment are bidirectional.

=== The database

For the sake of the training we will be working with H2 database engine to create our database schema.
We will be using flyway to migrate our database scheme.

You can check that your schema is valid running AppointmentBookingAppApplication.java which recreates schema after each run. Created schema can be found in the H2 console.

image::images/dataaccess/dataaccess_database_uml.png[width="500", link="images/dataaccess/dataaccess_database_uml.png"]

Lets start with the database schema. Create a new sql file _V0001__Create_schema.sql_ in appointment-booking-app/src/main/resources/db/migration/1.0/ folder.

==== _USER_TABLE_ table

We will add our first table USER_TABLE in /appointment-booking-app/src/main/resources/db/migration/1.0/V0001__Create_schema.sql. In the case of AppointmentBookingService, the Users will provide: id, version, email etc. Additionally, emails need to be unique among all users. So we need to represent that data in our table:

[source,sql]
----
CREATE TABLE USER_TABLE (
    ID NUMBER(19,0) NOT NULL,
    VERSION INTEGER NOT NULL,
    EMAIL VARCHAR(128) NOT NULL,
    PASSWORD_HASH VARCHAR(128) NOT NULL,
    FIRST_NAME VARCHAR(128) NOT NULL,
    LAST_NAME VARCHAR(128) NOT NULL,
    CREATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    LAST_UPDATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (ID),
    CONSTRAINT UNIQUE_USER_EMAIL UNIQUE (EMAIL)
);
----
 
- ID: the id for each item, automatically incremented using sequence HIBERNATE_SEQUENCE.
- VERSION: used internally by JPA to take care of the optimistic locking for us.
- CREATED: informs, when the entity was first created and saved. Default: current point in time
- LAST_UPDATED: informs, when the entity was last updated. Default: current point in time
- EMAIL: Email address of the user. Unique.
- PASSWORD_HASH: a secure way to store passwords in the database (further described in the Security Part of the exercises).
- FIRST_NAME: User's first name
- LAST_NAME: User's last name
 
We will also set the constraints:

- primary key for id to take care of it's uniqueness.
- UNIQUE_USER_EMAIL unique constraing for email column.

Notice, how we are using *USER_TABLE* instead of just *USER* as a name. USER is a reserved word, and we can't create a table with that name.

==== _CLIENT_ table

We will now add the CLIENT table in `/appointment-booking-app/src/main/resources/db/migration/1.0/V0001__Create_schema.sql`.  
Each Client is associated with a User, meaning there is a **one-to-one relationship** between the CLIENT and USER_TABLE. We add the *ON DELETE CASCADE* clause, because Client can't exist without a User - and if the User is deleted, the Client should be removed as well.  

[source,sql]
----
CREATE TABLE CLIENT (
    ID NUMBER(19,0) NOT NULL,
    VERSION INTEGER NOT NULL,
    USER_ID NUMBER(19,0) NOT NULL,
    CREATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    LAST_UPDATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (ID),
    FOREIGN KEY (USER_ID) REFERENCES USER_TABLE(ID) ON DELETE CASCADE
);
----

- ID: the unique identifier for each client, automatically incremented.
- VERSION: used internally by JPA to handle optimistic locking.
- CREATED: informs, when the entity was first created and saved. Default: current point in time
- LAST_UPDATED: informs, when the entity was last updated. Default: current point in time
- USER_ID: a reference to the associated user in the USER_TABLE.

We will also set the constraints:

- primary key for ID to ensure uniqueness.
- foreign key constraint linking USER_ID to the USER_TABLE.

Since a User can either be a Client or a Specialist (but not both), this table ensures proper role separation in the system.

==== _SPECIALIST_ table

Now lets add the SPECIALIST table.
Each Specialist is associated with a User, meaning there is a **one-to-one relationship** between the SPECIALIST and USER_TABLE.  
Additionally, a Specialist has a specialization field to describe their expertise.

The table should contain following columns:

- ID: the unique identifier for each specialist, automatically incremented.
- VERSION: used internally by JPA for optimistic locking.
- CREATED: informs, when the entity was first created and saved. Default: current point in time
- LAST_UPDATED: informs, when the entity was last updated. Default: current point in time
- SPECIALIZATION: the field of expertise for the specialist (e.g. "Dentist", "Orthopaedist").
- USER_ID: a reference to the associated user in the USER_TABLE.

We will also set the constraints:

- primary key for ID to ensure uniqueness.
- foreign key constraint linking USER_ID to the USER_TABLE. Remember about *ON DELETE CASCADE* clause.

==== _TREATMENT_ table

Now lets add the TREATMENT table.
Each Treatment is provided by a Specialist, meaning there is a **many-to-one relationship** between the TREATMENT and SPECIALIST.

[source,sql]
----
CREATE TABLE TREATMENT (
(...)
SPECIALIST_ID NUMBER(19,0),
(...)
FOREIGN KEY (SPECIALIST_ID) REFERENCES SPECIALIST(ID) ON DELETE CASCADE
);
----

In this case, we also assume, that a treatment should be removed, if the specialist is removed.

The table should contain following columns:

- ID: the unique identifier for each treatment, automatically incremented.
- VERSION: used internally by JPA for optimistic locking.
- CREATED: informs, when the entity was first created and saved. Default: current point in time
- LAST_UPDATED: informs, when the entity was last updated. Default: current point in time
- NAME: the name of the treatment (e.g., "Relaxing Massage").
- DESCRIPTION: a detailed description of the treatment.
- DURATION_MINUTES: the estimated duration of the treatment in minutes.
- SPECIALIST_ID: a reference to the Specialist providing the treatment.

We will also set the constraints:

- primary key for ID to ensure uniqueness.
- foreign key constraint linking SPECIALIST_ID to the SPECIALIST table.

==== _APPOINTMENT_ table

Finishing off, lets add the APPOINTMENT table.
Each Appointment is booked by a Client and is associated with a specific Treatment.  
This means there are **many-to-one relationships** between APPOINTMENT and both CLIENT and TREATMENT, which means two foreign keys for the APPOINTMENT table.

The table should contain following columns:

* ID: the unique identifier for each appointment, automatically incremented.
* VERSION: used internally by JPA for optimistic locking.
- CREATED: informs, when the entity was first created and saved. Default: current point in time
- LAST_UPDATED: informs, when the entity was last updated. Default: current point in time
* DATE_TIME: the scheduled date and time for the appointment.
* END_DATE_TIME: end timestamp of appointment
* STATUS: the current status of the appointment (default value: `SCHEDULED`), which can be:
** `SCHEDULED`: Appointment is booked but not yet completed.
** `CANCELLED`: Appointment has been canceled.
** `COMPLETED`: Appointment has been completed successfully. 
* CLIENT_ID: a reference to the Client who booked the appointment.
* TREATMENT_ID: a reference to the Treatment associated with the appointment.

We will also set the constraints:

- primary key for ID to ensure uniqueness.
- foreign key constraint linking CLIENT_ID to the CLIENT table - with *ON DELETE CASCADE* clause
- foreign key constraint linking TREATMENT_ID to the TREATMENT table - with *ON DELETE CASCADE* clause

A Client can book multiple Appointments, and a Treatment can have multiple Appointments, but each Appointment is linked to a single Client and a single Treatment.

==== SEQUENCES

To provide a generation strategy for our technical IDs, lets provide some sequences for our tables and entities.
First create a sequence for a user:

[source, sql]
----
CREATE SEQUENCE USER_SEQ START WITH 1 INCREMENT BY 100 NOCYCLE;
----

The sequence will start with 1, and each call for next_val will return the value from previus next_val call, with 100 added to it (first 101, then 201, 301 and so on). 
Nocycle means, the sequence will not start all over again when it reaches the max value.

Now create the sequences for all your entities basing off of the sequence for user.

==== CONSTRAINT CHECKS

END_DATE_TIME > DATE_TIME. How would you ensure this using Check Constraint?

==== INDEXES

Indexes can significantly improve query performance by allowing the database to quickly locate and access rows in a table based on specific columns. It’s important to create indexes on columns that are frequently used in `WHERE` clauses, `JOIN` conditions, or `ORDER BY` statements.

Creating an index on a foreign key column in Oracle is a good practice — especially to avoid full table locks when the parent table rows are updated or deleted.

Create an index for the `USER_ID` column in the `CLIENT` table:

[source,sql]
----
CREATE INDEX IDX_CLIENT_USER ON CLIENT(USER_ID);
----

Now create the indexes for all your foreign keys across tables.


==== Mockdata
Finally we can provide a certain amount of mock data to start our app. Add a new sql script /appointment-booking-app/src/main/resources/db/migration/1.0/V0002__Create_mockdata.sql adding sample data:

[%nowrap,sql]
----
-- USERS - Clients
INSERT INTO USER_TABLE(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) VALUES (-1, 0, 'Stefan', 'Kowalski', 'passwordHash1', 'stefan.kowalski@gmail.com', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO USER_TABLE(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) VALUES (-2, 0, 'Anna', 'Nowak', 'passwordHash2', 'annan@yahoo.com', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO USER_TABLE(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) VALUES (-3, 0, 'Luiza', 'Poniatowska', 'passwordHash3', 'poniatowskaluiza@o2.pl', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO USER_TABLE(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) VALUES (-4, 0, 'Grzegorz', 'Maniewicz', 'passwordHash4', 'g.maniewicz@gmail.com', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);

-- USERS - Specialists
INSERT INTO USER_TABLE(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) VALUES (-5, 0, 'Dobromir', 'Zegula', 'passwordHash5', 'zegula.d@gmail.com', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO USER_TABLE(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) VALUES (-6, 0, 'Monika', 'Siewiczowa', 'passwordHash6', 'monika.s@yahoo.com', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO USER_TABLE(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) VALUES (-7, 0, 'Andrzej', 'Piaseczny', 'passwordHash7', 'a.j.piaseczny@o2.pl', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO USER_TABLE(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) VALUES (-8, 0, 'Patrycja', 'Milewska', 'passwordHash8', 'milewskap@gmail.com', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);

-- CLIENTS
INSERT INTO CLIENT(ID, VERSION, USER_ID, CREATED, LAST_UPDATED) VALUES (-1, 0, -1, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO CLIENT(ID, VERSION, USER_ID, CREATED, LAST_UPDATED) VALUES (-2, 0, -2, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO CLIENT(ID, VERSION, USER_ID, CREATED, LAST_UPDATED) VALUES (-3, 0, -3, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO CLIENT(ID, VERSION, USER_ID, CREATED, LAST_UPDATED) VALUES (-4, 0, -4, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);

-- SPECIALISTS
INSERT INTO SPECIALIST(ID, VERSION, USER_ID, SPECIALIZATION, CREATED, LAST_UPDATED) VALUES (-1, 0, -5, 'Dentist', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO SPECIALIST(ID, VERSION, USER_ID, SPECIALIZATION, CREATED, LAST_UPDATED) VALUES (-2, 0, -6, 'Cardiologist', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO SPECIALIST(ID, VERSION, USER_ID, SPECIALIZATION, CREATED, LAST_UPDATED) VALUES (-3, 0, -7, 'Pediatrician', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO SPECIALIST(ID, VERSION, USER_ID, SPECIALIZATION, CREATED, LAST_UPDATED) VALUES (-4, 0, -8, 'Orthopaedist', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);

-- TREATMENTS
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-1, 0, 'Konsultacja dentystyczna', 'Konsultacja dentystyczna z diagnostyką i planem leczenia', 30, -1, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-2, 0, 'Leczenie kanałowe', 'Leczenie kanałowe pojedynczego zęba ze znieczuleniem', 120, -1, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-3, 0, 'Konsultacja kardiologiczna', 'Konsultacja kardiologiczna z wstępną diagnostyką', 30, -2, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-4, 0, 'USG serca', 'USG serca z diagnostyką', 45, -2, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-5, 0, 'Konsultacja pediatryczna', 'Konsultacja pediatryczna w przypadku choroby', 20, -3, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-6, 0, 'Bilans 2-latka', 'Bilans dwulatka z przygotowaniem dokumentacji', 40, -3, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-7, 0, 'Wymaz z nosogardła', 'Wymaz pobierany z części nosowej gardła w celu diagnostycznym', 10, -3, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-8, 0, 'Bilans 5-latka', 'Bilans pięciolatka z przygotowaniem dokumentacji', 40, -3, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-9, 0, 'Płukanie żołądka', 'Interwencyjne płukanie żołądka', 30, -3, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-10, 0, 'Konsultacja ortopedyczna', 'Konsultacja ortopedyczna z diagnostyką', 30, -4, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-11, 0, 'Usunięcie haluksów', 'Operacja usunięcia haluksów z korekcję torebki stawowej i ścięgien', 75, -4, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO TREATMENT(ID, VERSION, NAME, DESCRIPTION, DURATION_MINUTES, SPECIALIST_ID, CREATED, LAST_UPDATED) VALUES (-12, 0, 'Rekonstrukcja więzadła ACL', 'Rekonstrukcją więzadła krzyżowego przedniego (ACL) z zastąpieniem uszkodzonego więzadła nowym więzadłem ze ścięgien pacjenta.', 180, -4, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);

-- APPOINTMENTS
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-1, 0, -1, -1,  '2024-03-01 09:00:00', '2024-03-01 09:15:00',  'SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-2, 0, -2, -3,  '2024-03-02 10:30:00', '2024-03-02 10:45:00',  'COMPLETED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-3, 0, -3, -5,  '2024-03-03 14:00:00', '2024-03-03 14:15:00',  'CANCELLED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-4, 0, -4, -10, '2024-03-04 08:15:00', '2024-03-04 08:30:00', 'SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-5, 0, -1, -2,  '2024-03-05 11:45:00', '2024-03-05 12:00:00',  'COMPLETED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-6, 0, -2, -4,  '2024-03-06 16:30:00', '2024-03-06 16:45:00',  'SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-7, 0, -3, -6,  '2024-03-07 09:30:00', '2024-03-07 09:45:00',  'CANCELLED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-8, 0, -4, -11, '2024-03-08 13:45:00', '2024-03-08 14:00:00', 'SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-9, 0, -1, -7,  '2024-03-09 10:00:00', '2024-03-09 10:15:00',  'COMPLETED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-10, 0, -2, -8, '2024-03-10 12:30:00', '2024-03-10 12:45:00', 'SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-11, 0, -3, -9, '2024-03-11 15:00:00', '2024-03-11 15:15:00', 'CANCELLED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-12, 0, -4, -12,'2024-03-12 17:15:00', '2024-03-12 17:30:00','SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-13, 0, -1, -1, '2024-03-13 08:30:00', '2024-03-13 08:45:00', 'COMPLETED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-14, 0, -2, -3, '2024-03-14 11:00:00', '2024-03-14 11:15:00', 'SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-15, 0, -3, -5, '2024-03-15 13:00:00', '2024-03-15 13:15:00', 'CANCELLED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-16, 0, -4, -10,'2024-03-16 09:15:00', '2024-03-16 09:30:00','SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-17, 0, -1, -2, '2024-03-17 14:45:00', '2024-03-17 15:00:00', 'COMPLETED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-18, 0, -2, -4, '2024-03-18 16:00:00', '2024-03-18 16:15:00', 'SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-19, 0, -3, -6, '2024-03-19 10:45:00', '2024-03-19 11:00:00', 'CANCELLED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
INSERT INTO APPOINTMENT(ID, VERSION, CLIENT_ID, TREATMENT_ID, DATE_TIME, END_DATE_TIME, STATUS, CREATED, LAST_UPDATED) VALUES (-20, 0, -4, -11,'2024-03-20 12:15:00', '2024-03-20 12:30:00','SCHEDULED', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);
----

You can provide your own data or use the script above.

Run application and check that the data you provided is inserted into the database.

=== Entities
==== Lombok Setup 
If you don't have the lombok dependency yet, add it to the pom.xml:
[source, xml]
----
<dependency>
	<groupId>org.projectlombok</groupId>
	<artifactId>lombok</artifactId>
	<scope>provided</scope>
</dependency>
----

You might have to install lombok separately in your IDE for the lombok annotations to work.

==== Creating the package structure

Now that we have defined the database for our entities, it's time to start creating the code of the related components.

We are going to create entities in new package _dataaccess_ which will contain all objects specific for our layer.

Create package _dataaccess.entity_ under _com.capgemini.training.appointmentbooking_ where we will place our entities.

image::images/dataaccess/dataaccess_package_creation_1.png[width="700", link="images/dataaccess/dataaccess_package_creation_1.png"]
image::images/dataaccess/dataaccess_package_creation_2.png[width="500", link="images/dataaccess/dataaccess_package_creation_2.png"]

You can create _dataaccess.converter_ and _common.datatype_ as well, since we will be using these packages in the next steps.

==== BaseEntity

Notice, that attributes _version_, _lastUpdated_ and _created_ are repeated in every entity. To make the structure cleaner and avoid duplicated code, let's extract a @MappedSuperclass, that each of our entities will extend.
Create a new class in package _com.capgemini.training.appointmentbooking.dataaccess.entity_:
[source,java]
----
@MappedSuperclass
@Getter
public class BaseEntity {
	
	@Version
	@Setter
	private int version;

	@Column(insertable = true, updatable = false)
	private Instant created;
	
	@Column(name="LAST_UPDATED")
	private Instant lastUpdated;
	
}
----

It has three attributes:

* _version_ - describing the version of the entity for optimistic locking. Only attribute with a setter
* _created_ and _lastUpdated_ attributes. Notice, they don't have the setters - the direct access to there attributes is not allowed. We will set them in our lifecycle listeners.
Add a listener with *@PrePersist*:
[source,java]
----

	@PrePersist
	public void prePersist() {
		Instant now = Instant.now();
		this.created = now;
		this.lastUpdated = now;
	}

----

This will set the fields just before the entity is saved fort the first time.
Now add a second listener with *@PreUpdate*, that will only update the _lastUpdated_ field, just before executing an update query.

Now you are ready to create your entities!

==== UserEntity

Create a new class _UserEntity_ in the same package.

Mark the class with `@Entity` and `@Table` annotations, specifying the table name. Let the class extend our @MappedSuperclass _BaseEntity_ to inherit the attributes _version_, _created_ and _lastUpdated_. 
Additionally, mark the class with `@Getters` and `@Setters` annotations from lombok - this will allow a getter and setter generation "in the background", without adding them in the class.

Define private attributes based on the schema (_id, email, passwordHash, firstName, lastName_).

Now, lets configure the _id_ attribute.

* Mark the _id_ attribute with `@Id`. 
* Add `@GeneratedValue` annotation, with `(strategy = GenerationType.SEQUENCE, generator = "USER_SEQ_GEN")`. This defines the generation strategy (in our case - sequence) and a generator name.
* Add `@SequenceGenerator` annotation. Define the _name_ as _USER_SEQ_GEN_ as you specified in `@GeneratedValue` annotation. 
Define _sequenceName_ as _USER_SEQ_. This binds the sequence we previously defined in sql with our _id_ attribute in _UserEntity_ class. 
Set the _allocationSize_ and _initialValue_ to match the definition from sql.

To ensure correct mapping to the database, add the `@Column` annotation with a specified name where needed (where the name in the database is not 1:1 with the name in java).

[source,java]
----
@Entity
@Table(name = "USER_TABLE")
@Getter
@Setter
public class UserEntity {
    @Id
	@GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "USER_SEQ_GEN")
	@SequenceGenerator(sequenceName = "USER_SEQ", name = "USER_SEQ_GEN", allocationSize = 100, initialValue = 1)
	private Long id;
	
	private String email;
	
	@Column(name="PASSWORD_HASH")
	private String passwordHash;
    
(...)
}

----

==== ClientEntity

Next to the UserEntity create ClientEntity. Mark the class with proper annotations, extend the _BaseEntity_ class.
Prepare attributes as shown in the schema. 
For Id use the same annotations, as in UserEntity to define the generation strategy and sequence generator. 
Remember to use a different name for a generator and an already created sequence for Client.
 
Now, lets implement the **uni-directional @OneToOne relationship** between the Client and the User. 
ClientEntity will be the owner of the relationship. Add a private attribute of type UserEntity in ClientEntity. Mark it with @OneToOne annotation and specify, that the relationship is not optional. Specify the cascade operations - only cascade _Persist_ operation. 
Define fetch type as lazy.
Additionally, you can add a @JoinColumn annotation, which will precisely describe what is the name of the Foreign Key column in the database in the CLIENT table, and which column it references in USER_TABLE table.

[source,java]
----
    @OneToOne(optional = false, fetch = FetchType.LAZY, cascade = { CascadeType.PERSIST })
    @JoinColumn(name = "USER_ID", referencedColumnName = "ID")
    private UserEntity user;
----

We will add the **bi-directional @ManyToOne relationship** to AppointmentEntity later on.

==== SpecialistEntity

Next to the previous entities create _SpecialistEntity_. Mark the class with proper annotations, extend _BaseEntity_.  
Prepare attributes as shown in the schema. For _id_ use the same annotations as in _UserEntity_ and a proper sequence.

For specialization attribute, *create an Enum* _Specialization_ in _/common/datatype_ package:

[source,java]
----
public enum Specialization {
	
	DENTIST("Dentist"), 
	CARDIOLOGIST("Cardiologist"), 
	PEDIATRICIAN("Pediatrician"), 
	UROLOGIST("Urologist"), 
	NEUROLOGIST("Neurologist"), 
	ORTHOPAEDIST("Orthopaedist");
	
	private String name;

	private Specialization(String name) {
		this.name = name;
	}

	public String getName() {
		return this.name;
	}
	
	public static Specialization getByName(String name) {

		for (Specialization s : Specialization.values()) {
			if (s.getName().equals(name)) {
				return s;
			}
		}
		return null;
	}
	
}
----

The _getByName_ method will be needed for our converter. 

But before that, let’s implement the **uni-directional @OneToOne relationship** between _SpecialistEntity_ and _UserEntity_.  
_SpecialistEntity_ will be the owner of the relationship.  
Add a private attribute of type _UserEntity_ in _SpecialistEntity_. Mark it with `@OneToOne` annotation and define as non-optional. Specify the cascade operations - only cascade _Persist_ operation. 
Define fetch type as lazy. 
Additionally, you can use `@JoinColumn` to specify the foreign key column in the _SPECIALIST_ table and its reference in _USER_TABLE_.

To ensure correct mapping to the database, add the `@Column` annotation with a specified name where needed.

We will add the **bi-directional @OneToMany relationship** to _TreatmentEntity_ later on.

===== Converting the specialization attribute

Now, let’s implement an **Attribute Converter** for the `Specialization` enum.  

In JPA, an `@Converter` allows us to customize how an enum is stored in the database.  
By default, JPA can store enums as **ordinal values** (integers) or **names** (string representations of enum constants).  
However, in our case, we want to store the **custom name field** of the `Specialization` enum instead of its default `name()`.  

To achieve this, we will:  
- Create a new class `SpecializationConverter` in package _/dataaccess/converter_ 
- Implement `AttributeConverter<Specialization, String>`  
- Override the `convertToDatabaseColumn(Specialization specialization)` method to return `specialization.getName()`  
- Override the `convertToEntityAttribute(String dbData)` method to use `Specialization.getByName(dbData)`  
- Mark the class with `@Converter`

====== a. Implementation

[source,java]
----
import jakarta.persistence.AttributeConverter;
import jakarta.persistence.Converter;

@Converter
public class SpecializationConverter implements AttributeConverter<Specialization, String> {

    @Override
	public String convertToDatabaseColumn(Specialization specialization) {
		
		return specialization != null ? specialization.getName() : null;
	}

    @Override
    public Specialization convertToEntityAttribute(String dbData) {
        if (dbData == null) {
            return null;
        }
        return Specialization.getByName(dbData);
    }
}
----

====== b. Usage in SpecialistEntity

To ensure the conversion is applied, annotate the `specialization` field in _SpecialistEntity_ with `@Convert(converter = SpecializationConverter.class)`.  

[source,java]
----
@Convert(converter = SpecializationConverter.class)
private Specialization specialization;
----

We could also mark the Converter as `@Converter(autoApply = true)`, so that JPA automatically applies it to all entity fields of type `Specialization`.
If we do so, we **don’t need to explicitly annotate each occurrence of Specialization**, as JPA will apply the converter automatically.  

Important to note - annotation @Enumerated and @Convert can not coexist! You have to either use one or another.

==== TreatmentEntity

Next to other entities create _TreatmentEntity_. Mark the class with proper annotations, extend the _BaseEntity_.  
Prepare attributes as shown in the schema. Use the same annotations for _id_ as in _UserEntity_, use proper sequence.

Now, let’s implement the **bi-directional @ManyToOne relationship** between _TreatmentEntity_ and _SpecialistEntity_.  
_TreatmentEntity_ will be the owning side and will hold information about the specialist providing the treatment.  
Add a private attribute of type _SpecialistEntity_ in _TreatmentEntity_. Mark it with `@ManyToOne` and define the fetch type as lazy.  
Additionally, you can use `@JoinColumn` to specify the foreign key column (but it's not necessary).

[source,java]
----
    @ManyToOne(fetch = FetchType.LAZY)
    private SpecialistEntity specialist;
}
----

Even though _TreatmentEntity_ is the owner, we also want _SpecialistEntity_ to hold information about the treatments provided by a specialist.  

Edit _SpecialistEntity_ and add an additional private attribute of type `List<TreatmentEntity>`.  
Mark the attribute with `@OneToMany`, defining which attribute this relationship is mapped by, and the cascade types - only _Persist_ and _Remove_ (we don't want the Treatment to exist without a relationship to a Specialist).
Add orphanRemoval=true, so that the Appointment will be removed, then the connection between Client and Appointment is broken.
You can add a fetchType `LAZY` as well, it's a default type in this case though.

[source,java]
----
@OneToMany(mappedBy = "specialist", fetch = FetchType.LAZY, orphanRemoval = true, cascade = { CascadeType.PERSIST, CascadeType.REMOVE })
private List<TreatmentEntity> treatments;
----

==== AppointmentEntity

Next to the previous entities create _AppointmentEntity_. Mark the class with proper annotations, extend the _BaseEntity_ class.
Prepare attributes as shown in the schema. Use the same annotations for _id_ as in _UserEntity_. Remember about the sequence.

For _status_ attribute, create a simple enum AppointmentStatus next to the _Specialization_ enum:

[source,java]
----
public enum AppointmentStatus {
SCHEDULED, CANCELLED, COMPLETED;
}
----

Don't forget the @Enumerated annotation here, with EnumType.STRING.

Now, let’s implement **bi-directional @ManyToOne relationship** between _AppointmentEntity_ and _ClientEntity_.  
_AppointmentEntity_ is the owning side and will store a reference to the client booking the appointment.

Add a private attribute of type _ClientEntity_ in _AppointmentEntity_.  
Mark it with `@ManyToOne` annotation, specify the fetch type as lazy.

Even though _AppointmentEntity_ is the owner, we also want _ClientEntity_ to hold a reference to the appointments booked by a client.  

Edit _ClientEntity_ and add a private attribute of type `List<AppointmentEntity>`.  
Mark it with `@OneToMany`, specifying the mapped attribute, orphanRemoval, fetch type and cascade types. 

[source,java]
----
@OneToMany(mappedBy = "client", fetch = FetchType.LAZY, orphanRemoval=true, cascade = { CascadeType.PERSIST, CascadeType.REMOVE })
private List<AppointmentEntity> appointments;
----

Additionally, let’s implement the **uni-directional @ManyToOne relationship** between AppointmentEntity and TreatmentEntity.
AppointmentEntity will store a reference to the treatment that the appointment is associated with, but TreatmentEntity will not store any reference to AppointmentEntity.
This means we only define the relationship in AppointmentEntity, making it a one-way connection.

Add a private attribute of type TreatmentEntity in AppointmentEntity.
Mark it with @ManyToOne annotation. Define fetch type as lazy.

==== EntitySmokeIT

Now that entity mappings are in place, let’s verify whether they are correctly loaded from the database.  
Create a new test class named _EntitySmokeIT_ in _src/main/test_, under _com.capgemini.training.appointmentbooking.dataaccess.entity_. Annotate it with `@DataJpaTest(bootstrapMode = BootstrapMode.LAZY)` to configure JPA-related components.

Inside the class, inject an instance of `EntityManager` using `@PersistenceContext`.

Now, implement a test method that will validate the database contains the expected number of records for each entity.

[source,java]
----
    @Test
    void loadAllClasses() {

        // given
        Map<Class<? extends BaseEntity>, Integer> classMap = Map.of(
                UserEntity.class, 8,
                ClientEntity.class, 4,
                SpecialistEntity.class, 4,
                TreatmentEntity.class, 12,
                AppointmentEntity.class, 20
        );

        // when //then
        classMap.forEach((entityType, expectedCount) ->
                assertThat(em.createQuery("from " + entityType.getSimpleName()).getResultList()).hasSize(expectedCount));
    }
}
----

For each entity type, we define the expected number of records in a map.

Using `EntityManager`, we execute a simple query `"from <EntityName>"` to fetch all records of a given entity type.

We then validate that the number of retrieved records matches the expected count.

You are ready to go!

=== Repositories

To perform operations on our entities we need to create repositories for each of them. They will contain operations specific for each of the objects.
Repositories used in Spring are already defined as Interface called _Repository_. There are multiple extensions of this interface and we will use _JpaRepository<ENTITY, ID>_.

==== Create custom repository infrastructure
In complex projects, it is recommended to consider creating a custom repository interface.
Advanced use cases often require the use of sophisticated mechanisms provided by the EntityManager. For this reason, we will create our own repository interface.

===== Custom repository interface
Create custom _JpaRepository_ interface that will enable access to _EntityManager_

[source,java]
----
package com.capgemini.training.appointmentbooking.dataaccess.repository;

@NoRepositoryBean
public interface BaseJpaRepository<T, ID> extends JpaRepository<T, ID> {
    EntityManager getEntityManager();
}
----

===== Custom repository implementation
Create custom repository implementation

[source,java]
----
package com.capgemini.training.appointmentbooking.dataaccess.repository.impl;

public class BaseJpaRepositoryImpl<T, ID> extends SimpleJpaRepository<T, ID> implements BaseJpaRepository<T, ID> {

    private final EntityManager entityManager;

    BaseJpaRepositoryImpl(JpaEntityInformation<T, ?> entityInformation, EntityManager entityManager) {
        super(entityInformation, entityManager);
        this.entityManager = entityManager;
    }

    @Override
    public EntityManager getEntityManager() {
        return this.entityManager;
    }

}
----

===== Configure Spring to use custom repositories
Now we need to configure Spring to use our custom repository
[source,java]
----
package com.capgemini.training.appointmentbooking.dataaccess.config;

@Configuration
@EnableJpaRepositories(
    repositoryBaseClass = BaseJpaRepositoryImpl.class,
    basePackages = "com.capgemini.training.appointmentbooking.dataaccess.repository")
public class DataaccessConfiguration {}
----

==== AppointmentRepository

In the component appointmentbooking, create package dataaccess.repository. We will place there all our repositories.

Create interface _AppointmentRepository_. It should extend _JpaRepository_ from Spring which contains all basic operations along with methods used in sorting and paging of results. This Interface is generic.
[source,java]
----
public interface AppointmentRepository extends BaseJpaRepository<AppointmentEntity, Long> {
    // Add imports and that's it
}
----

==== Create basic dataaccess layer integration tests infrastructure
First we will create a _BaseTest_ that will enable AssertJ assertions.

[source, java]
----
package com.capgemini.training.appointmentbooking.common;

public class BaseTest implements WithAssertions {

    protected Instant toInstant(String date) {
        DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");
        return LocalDateTime.parse(date, formatter).atZone(ZoneId.systemDefault()).toInstant();
    }
}
----

Then we create a base class for dataaccess layer integration test.

[source, java]
----
package com.capgemini.training.appointmentbooking.common;

@DataJpaTest
@Import(DataaccessConfiguration.class)
public class BaseDataJpaTest extends BaseTest{
}
----

The _BaseDataJpaTest_ enables

* Persistance integration testing via _@DataJpaTest_ annotation
* Support for transaction (and automatic rollback) (inherited from _@DataJpaTest_ annotation)
* Usage of our custom repository implementation via _@Import_ annotation

@DataJpaTest creates us a simplified Spring Test configuration with loaded Entities and repositories.
All of the tests on @DataJpaTest will be launched on preconfigured H2 Database, so there's no configuration needed.
Remember, that by default all @Test methods in a @DataJpaTest annotated test class will be automatically rolled back and not commited.
This actually may cause some of your database-specific constraints to not be actually checked, only your Entity annotations
- and that's a plus, because the tests are much faster, and you should add constraints to BOTH db and Entities.
Just like you should do frontend AND backend validation.



==== AppointmentRepositoryIT

With a standard repository we can already perform basic CRUD operations, f.e. save, deleteById, findById.

We can test the behaviour of Repository methods using unit tests. Remember that we do not test the framework itself but our usage of it. Still writing test for simple CRUD operations is usually not needed. We will write some simple tests nevertheless, just to understand the structure and behaviour of repository tests using @DataJpaTest

In source folder src/test/java of project create same package as for interface.
Alternatively, you can use IDE to generate test in corresponding package but in srt/test/java folder.
This will enable you to test this class package protected (default visibility) methods.
Create the class _AppointmentRepositoryTest_. Remember to add imports.
[source,java]
----
public class AppointmentRepositoryIT extends BaseDataJpaTest {}
----


===== FindAll test

Let's write our first test - we would like to find all entities.
We will use for it findAll() method which is available in _AppointmentRepository_ thanks to inheritance of _JpaRepository_.
Spring then creates a proxy classes of all Interfaces extending the Spring repositories, because Spring is still java,
and you cannot have instances of interfaces.

- inject _AppointmentRepository_ to test class.
- prepare public method annotated with _@Test_
- call there _appointmentRepository.findAll()_ method
- check that number of found elements is same as number of elements created in your migration.
- imports

[source,java]
----
public class AppointmentRepositoryIT extends BaseDataJpaTest {

    @Autowired
    private AppointmentRepository appointmentRepository; //some IDE's wrongfully mark this var as unused

    @Test
    void testFindAll() {
        //given
        // when
        List<AppointmentEntity> result = appointmentRepository.findAll();

        //then
        assertThat(result).isNotEmpty();
        assertThat(result).hasSize(20);
    }
}

----

To run the tests, right click and select run tests.

You should also see some hibernate queries, they may be difficult to read but it's there.

[source,java]
----
Hibernate: select ae1_0.id,ae1_0.client_id,ae1_0.created,ae1_0.date_time,ae1_0.last_updated,ae1_0.status,ae1_0.treatment_id,ae1_0.version from appointment ae1_0
----

You can also use the mvn command:
[source,bash]
----
mvn test
----

Wonderful job! You've created your first Test using Spring Repositories and _@DataJpaTest_.
You may have also heard of _@SpringBootTest_. You can try and switch it up to see the difference.
_@SpringBootTest_'s are slower, but also allow you to test web communication and they search for
_@SpringBootConfiguration_ when required, allowing you to overwrite configuration for testing purposes.

Regardless JPA Testing, those annotations seem same at first, but it's much easier to connect yourself to an other database,
be it in local or in remote test environment and check if your database constraints etc. are working,
if your triggers, scripts or whatever else is working as intended too.
These tests use I/O intensively, so they are PAINFULLY slow and you need to maintain data stability between tests,
so developers need to implement proper measures. On top of that, we can throw parallel test launches out of the window.
Still, some projects use or require this approach, so it's worth noting.


=== Querying the Database

Spring Data Allows us to use a multitude of basic queries, but what if we want something customised?
Due to the age (Java developers prefer word "Maturity") of the language and JPA itself, multitude of different libraries,
Domain Specific Languages, frameworks etc. were introduced, to aid us or to make our lives more difficult.

In the end, it doesn't even matter - it's all always mapped to JPQL Query String, and called through entityManager, the core of JPA.
If you will debug deep enough, you will find it (try it if you're bored).
How you will use the JPA is usually decided by an architect or the developers themselves.

== Exercise No. 1

Implement those 2 queries and test them. Before you dive into the code, you may want to look at examples in paragraph below.

1) Find all Treatments with partially given name, ignoring upper and lowercase

2) Find all Appointments for specific Specialist which took place in the past (hint: join statement is needed here)


== Various Query Methods

Courtesy of Spring: https://docs.spring.io/spring-data/jpa/reference/jpa/query-methods.html

Example's of queries in given forms with explanation:

=== Spring Query Methods

Spring Query Methods is a mechanism used solely by Spring.
It can match the method name with corresponding table, due to Generic Type,
and add simple clauses just by interpreting the name of the methods. It will cause wierd exceptions if this cannot be parsed, so be advised!

In the _TreatmentRepository_ interface type:
[source,java]
----
List<TreatmentEntity> findAllByName(String name);
----
That's it.

==== Spring @Query Annotation

Directly in the interface create a new method with a @Query annotation and JQPL query inside.
@Param annotation is used to map the java var name of query variable

[source,java]
----
    @Query("""
            SELECT a FROM AppointmentEntity a
            JOIN a.treatment t
            WHERE t.specialist.id = :specialistId
            AND a.dateTime < :date
            ORDER BY a.dateTime DESC
            """)
    List<AppointmentEntity> findAppointmentsBySpecialistIdBeforeDate(@Param("specialistId") Long specialistId, @Param("date") Instant date);

----

==== Named Query + Named Method

We can predefine a NamedQuery in the Entity class as a query with a given name and query string.
You can use parameters there, but to use Spring mechanisms,
the name of the query needs to start with the name of the entity.

[source,java]
----
@NamedQuery(name = "SpecialistEntity.findBySpecialization",
    query = "select s from SpecialistEntity s where specialization =:specialization")
----


Then you can create a method in interface with same name:

[source,java]
----
List<SpecialistEntity> findBySpecialization(Specialization specialization);
----

If the name will match, then you will be able to run the named query from interface.

=== Custom Queries

To implement custom queries we need to have access to the _EntityManager_.
It is very easy since we have already created a _BaseJpaRepository_.

First, we need to define a class with the fields that will be used for searching.
Create a _UserCriteria_ class in the criteria package to encapsulate search parameters.

[source,java]
----
public record UserCriteria(String firstName, String lastName, String email) {
}
----

Now extend your own interface repository with _BaseJpaRepository_ and implement a method.

[source,java]
----
@Repository
public interface UserRepository extends BaseJpaRepository<UserEntity, Long> {
    default List<UserEntity> findByCriteria(UserCriteria criteria) {

        EntityManager entityManager = getEntityManager();
        // query the database using entityManager, criteria api or querydsl
    }
}
----

==== Criteria Api

It allows you to build somewhat customized, more complex queries, but the amount of boilerplate code is obnoxious. The boilerplate code will require two different "creator" classes to be instantiated and mixed with each other.
In the end the dev is forced to either build a horrific chain of subclasses to generalise some of the code, or, typically, copy-paste like the client would pay them for LoC.

Here's a working sample, you can copy-paste in most of the projects using Criteria API and you're golden.

In the _AppointmentRepository_ interface type:
[source,java]
----
default List<AppointmentEntity> findByCriteria(AppointmentCriteria appointmentCriteria, EntityManager entityManager) {
        Objects.requireNonNull(appointmentCriteria, "appointmentCriteria must not be null");

        CriteriaBuilder cb = entityManager.getCriteriaBuilder();
        CriteriaQuery<AppointmentEntity> cq = cb.createQuery(AppointmentEntity.class);
        Root<AppointmentEntity> root = cq.from(AppointmentEntity.class);
        List<Predicate> predicates = new ArrayList<>();

        if (c.status() != null) {
            predicateList.add(builder.like(root.get("status"), c.status().name()));
        }

        // another predicates

        cq.where(predicates.toArray(new Predicate[0]));
        return entityManager.createQuery(cq).getResultList();
    }
----


=== Query DSL

Criteria Api long lost step-brother. Everyone likes him more, he's cool. So what that (in older versions, don't know for sure now)
he will occasionally cut parts of your query WHERE clauses and won't add them to the query String, potentially causing catastrophic reads.
Imagine if that bad read would go to some batch processing.

Still, those errors are not that often, and the API is so nice and easy, that we forgive him.

To use QueryDSL along with its supportive QClasses we need to do the following:

Add these 2 dependencies to the pom.xml in the _<dependencies>_ block;
[source,xml]
----
		<dependency>
			<groupId>com.querydsl</groupId>
			<artifactId>querydsl-apt</artifactId>
			<version>5.0.0</version>
			<classifier>jakarta</classifier>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>com.querydsl</groupId>
			<artifactId>querydsl-jpa</artifactId>
			<classifier>jakarta</classifier>
			<version>5.0.0</version>
		</dependency>
----


Add this plugin in the _<plugins>_ block;

[source,xml]
----
<plugin>
    <groupId>com.mysema.maven</groupId>
	<artifactId>apt-maven-plugin</artifactId>
	<version>1.1.3</version>
	<executions>
		<execution>
			<goals>
				<goal>process</goal>
			</goals>
			<configuration>
				<outputDirectory>target/generated-sources/java</outputDirectory>
				<processor>com.mysema.query.apt.jpa.JPAAnnotationProcessor</processor>
			</configuration>
		</execution>
	</executions>
</plugin>
----

Clean and install the project.
In target.generated-sources/annotations there should be
_QApointmentEntity_, _QBaseEntity_, _QClientEntity_, _QSpecialistEntity_, _QTreatmentEntity_, _QUserEntity_ classes.

QueryDSL allows us to write us easy queries. In _ClientRepository_ we can add the method

[source,java]
----
@Repository
public interface ClientRepository extends BaseJpaRepository<ClientEntity, Long> {

    default List<ClientEntity> findByName(String firstName, String lastName, EntityManager entityManager) {
        JPAQueryFactory queryFactory = new JPAQueryFactory(entityManager);

        QClientEntity client = QClientEntity.clientEntity;
        QUserEntity user = QUserEntity.userEntity;

        return queryFactory
                .selectFrom(client)
                .leftJoin(client.user, user)
                .where(user.firstName.eq(firstName)
                        .and(user.lastName.eq(lastName)))
                .fetch();
    }
}
----

And then simply test it:

[source,java]
----
public class TreatmentRepositoryIT extends BaseDataJpaTest  {

    @Autowired
    private ClientRepository clientRepository;

    @PersistenceContext
    private EntityManager em;

    @Test
    void testFindByQueryDSL_testFindClientsByName() {
        // given
        String firstName = "Stefan";
        String lastName = "Kowalski";

        // when
        List<ClientEntity> clients = clientRepository.findByName(firstName, lastName, em);

        // then
        assertThat(clients).isNotEmpty().hasSize(1);
        ClientEntity client = clients.getFirst();
        assertNotNull(client.getUser(), "Expected client to have an associated user");
        assertEquals(firstName, client.getUser().getFirstname(), "Expected client to have the specified first name");
        assertEquals(lastName, client.getUser().getLastname(), "Expected client to have the specified last name");
    }
}
----

== Exercise No. 2:

Implement these queries:

1. Find appointments within a specified time period and having a designated status - using a Spring Query Method.
2. Find conflicted appointments for given specialistId,  begin date and end date of appointment (appointment in status CANCELLED is not a conflicting appointment)- using @Query.
3. Find treatment by name - using NamedQuery and bind it to interface method.
4. Find treatments by name and specialization - using QueryDSL.
5. Find appointments history for given client/specialist - using criteria API.

Remember to test your queries!

== Hints and Troubleshooting

During your implementation you may encounter multiple vague exceptions.
JPA Exceptions look sometimes like they are wrapped or hidden, so careful console logs analysis is required.
However, there are some exceptions that are more common than others:

[source, bash]
----
IllegalStateException: Failed to load ApplicationContext
----
This happens usually if the query you have created has errors and does not compile.
This is because queries are checked in runtime during startup (not compile-time) - that's why your code compiles,
but the test or app does not run.


== Navigation
[grid=cols]
|===
link:appointment-booking-system-specification.asciidoc[Previous Chapter: Appointment Booking System Specification] | link:appointment-booking-service-business-logic-layer.asciidoc[Next Chapter: Appointment Booking System - Logic Layer] =>
|===
