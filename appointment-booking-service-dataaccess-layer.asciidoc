:toc: macro
:sectnums:
:sectnumlevels: 3

= Appointment Booking System - Data Access Layer

In this chapter, we'll create a comprehensive database schema with initial data, map it to entity models, and implement operations for entity management. This forms the foundation of our appointment booking system's data persistence layer.

toc::[]

== Understanding the Domain Model

After completing the link:appointment-booking-service-setup.asciidoc[Appointment Booking System Setup], we'll create our domain model based on the requirements outlined in the link:appointment-booking-system-specification.asciidoc[Appointment Booking System Specification].

=== Core Functionalities

Our system must support these essential operations:

* Adding new `Treatments` associated with `Specialists`
* Retrieving available `Treatments`, optionally filtered by `Specialist` or `Treatment` name
* Retrieving detailed `Treatment` information including connected `Specialist` data
* Creating `Appointments` as a `Client` for specific dates and times
* Validating `Appointment` scheduling conflicts (preventing double-booking of `Specialists`)
* Allowing `Clients` to view their appointments
* Enabling `Appointment` cancellation by `Clients`
* Marking `Appointments` as completed by `Specialists`
* Optional: Retrieving visit history for `Clients` and `Specialists`

[NOTE]
====
*Think about it:* Why is preventing double-booking crucial for a medical appointment system? What could happen if two patients were scheduled with the same specialist at the same time?
====

=== Entity Overview

We'll work with five core entities: `UserEntity`, `ClientEntity`, `SpecialistEntity`, `TreatmentEntity`, and `AppointmentEntity`.

image::images/dataaccess/dataaccess_entities_uml.png[width="1000", link="images/dataaccess/dataaccess_entities_uml.png"]

==== Common Entity Attributes

Each entity includes these standard fields:

* `id` - Generated using database sequences
* `version` - Optimistic locking version number
* `created` - Entity creation timestamp
* `lastUpdated` - Last modification timestamp

==== Entity Specifications

* **UserEntity**: Contains `email` (unique), `passwordHash`, `firstName`, and `lastName`
* **ClientEntity**: Links to a `UserEntity` and maintains a collection of `AppointmentEntities`
* **SpecialistEntity**: Includes `specialization` (enum), links to a `UserEntity`, and maintains `TreatmentEntities`
* **TreatmentEntity**: Contains `name`, `description`, `duration` (minutes), and links to a `SpecialistEntity`
* **AppointmentEntity**: Includes `dateTime`, `status` (enum), and links to `ClientEntity` and `TreatmentEntity`

=== Relationship Mapping

Understanding these relationships is crucial for proper database design:

==== One-to-One Relationships
* **User ↔ Client**: Each user can optionally be a client
* **User ↔ Specialist**: Each user can optionally be a specialist

[IMPORTANT]
====
A user can be both a client and a specialist simultaneously. For example, a doctor (specialist) can also book appointments with other specialists as a client. This flexible design supports real-world scenarios where medical professionals may need services from other specialists.
====

==== One-to-Many Relationships
* **Specialist → Treatments**: One specialist provides multiple treatments
* **Client → Appointments**: One client can book multiple appointments
* **Treatment → Appointments**: One treatment can have multiple appointments

==== Bidirectional Relationships
Only `Client ↔ Appointment` and `Specialist ↔ Treatment` relationships are bidirectional, allowing navigation in both directions.

[NOTE]
====
*Think about it:* Why might we choose to make some relationships bidirectional while keeping others unidirectional? What are the trade-offs in terms of performance and complexity?

Consider this scenario: What happens when a user who is both a client and a specialist tries to book an appointment with themselves? How should the system handle this edge case?
====

== Database Configuration

=== Technology Stack

We'll use:
* **H2 Database**: In-memory database perfect for development and testing
* **Flyway**: Database migration tool for version control of schema changes

[WARNING]
====
H2 is excellent for development but should never be used in production. Production systems require persistent databases like PostgreSQL, MySQL, or Oracle.
====

=== Database Setup

Add these configurations to your `application.properties` file:

==== H2 Database Configuration
[source,properties]
----
spring.h2.console.enabled=true

spring.datasource.url=jdbc:h2:mem:appointmentbooking
spring.datasource.username=sa
spring.datasource.password=password
----

==== Flyway Configuration
[source,properties]
----
spring.flyway.locations=classpath:db/migration
spring.flyway.enabled=true
spring.flyway.clean-on-validation-error=true
----

[IMPORTANT]
====
The `clean-on-validation-error=true` setting will drop and recreate your database if migration validation fails. This is useful for development but dangerous in production!
====

=== Accessing the H2 Console

1. Start your application
2. Navigate to http://localhost:8080/h2-console/
3. Use the connection details configured above:

image::images/setup/h2-console-login.png[H2 Console - login]

After successful login:

image::images/setup/h2-console-content.png[H2 Console - content]

You should see this in your application logs:
[source,console]
----
... : H2 console available at '/h2-console'. Database available at 'jdbc:h2:mem:appointmentbooking'
... : Exposing 15 endpoints beneath base path '/actuator'
... : Tomcat started on port 8080 (http) with context path ''
----

[NOTE]
====
*Think about it:* Why is having a database console useful during development? How might this help you debug data-related issues?
====

=== Database Schema Design

Our schema follows these design principles:

[plantuml, database-schema, svg]
----
@startuml
entity APPLICATION_USER {
  *ID : NUMBER(19,0)
  *VERSION : INTEGER
  *EMAIL : VARCHAR(254) --RFC 5321
  *PASSWORD_HASH : VARCHAR(128)
  *FIRST_NAME : VARCHAR(128)
  *LAST_NAME : VARCHAR(128)
  *CREATED : TIMESTAMP
  *LAST_UPDATED : TIMESTAMP
  --
  UNIQUE_USER_EMAIL
}

entity CLIENT {
  *ID : NUMBER(19,0)
  *USER_ID : NUMBER(19,0)
  --
  FK_USER_ID
}

entity SPECIALIST {
  *ID : NUMBER(19,0)
  *USER_ID : NUMBER(19,0)
  *SPECIALIZATION : VARCHAR(128)
  --
  FK_USER_ID
}

entity TREATMENT {
  *ID : NUMBER(19,0)
  *NAME : VARCHAR(128)
  *DESCRIPTION : TEXT
  *DURATION_MINUTES : INTEGER
  *SPECIALIST_ID : NUMBER(19,0)
  --
  FK_SPECIALIST_ID
}

entity APPOINTMENT {
  *ID : NUMBER(19,0)
  *DATE_TIME : TIMESTAMP
  *END_DATE_TIME : TIMESTAMP
  *STATUS : VARCHAR(32)
  *CLIENT_ID : NUMBER(19,0)
  *TREATMENT_ID : NUMBER(19,0)
  --
  FK_CLIENT_ID
  FK_TREATMENT_ID
}

APPLICATION_USER ||--|| CLIENT : is a
APPLICATION_USER ||--|| SPECIALIST : is a
SPECIALIST ||--o{ TREATMENT : provides
CLIENT ||--o{ APPOINTMENT : books
TREATMENT ||--o{ APPOINTMENT : includes
@enduml
----

== Creating Database Tables

Create the migration file: `src/main/resources/db/migration/V0001__Create_schema.sql`

[IMPORTANT]
====
Flyway migration files must follow the naming convention: `V<version>__<description>.sql`. The version number determines execution order.
====

=== APPLICATION_USER Table

[source,sql]
----
CREATE TABLE APPLICATION_USER (
    ID NUMBER(19,0) NOT NULL,
    VERSION INTEGER NOT NULL,
    EMAIL VARCHAR(254) NOT NULL,
    PASSWORD_HASH VARCHAR(128) NOT NULL,
    FIRST_NAME VARCHAR(128) NOT NULL,
    LAST_NAME VARCHAR(128) NOT NULL,
    CREATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    LAST_UPDATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (ID),
    CONSTRAINT UNIQUE_USER_EMAIL UNIQUE (EMAIL)
);
----

==== Field Explanations

* **ID**: Primary key, auto-incremented via sequence
* **VERSION**: JPA optimistic locking version
* **EMAIL**: Unique identifier following RFC 5321 (max 254 characters)
* **PASSWORD_HASH**: Secure password storage (never store plain text!)
* **CREATED/LAST_UPDATED**: Audit timestamps with automatic defaults

[WARNING]
====
We use `APPLICATION_USER` instead of `USER` because `USER` is a reserved word in most SQL databases.
====

[NOTE]
====
*Think about it:* Why do we store password hashes instead of plain text passwords? What security risks would plain text passwords introduce?
====

=== CLIENT Table

[source,sql]
----
CREATE TABLE CLIENT (
    ID NUMBER(19,0) NOT NULL,
    VERSION INTEGER NOT NULL,
    USER_ID NUMBER(19,0) NOT NULL,
    CREATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    LAST_UPDATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (ID),
    FOREIGN KEY (USER_ID) REFERENCES APPLICATION_USER(ID) ON DELETE CASCADE
);
----

The `ON DELETE CASCADE` ensures that when a user is deleted, their client record is automatically removed, maintaining referential integrity.

=== SPECIALIST Table

**Exercise**: Create the SPECIALIST table following this specification:

* **ID**: Primary key (NUMBER(19,0))
* **VERSION**: Optimistic locking (INTEGER)
* **USER_ID**: Foreign key to APPLICATION_USER (NUMBER(19,0))
* **SPECIALIZATION**: Specialist's field of expertise (VARCHAR(128))
* **CREATED/LAST_UPDATED**: Audit timestamps

Remember to include:
* Primary key constraint
* Foreign key constraint with `ON DELETE CASCADE`
* Proper NOT NULL constraints

=== TREATMENT Table

[source,sql]
----
CREATE TABLE TREATMENT (
    ID NUMBER(19,0) NOT NULL,
    VERSION INTEGER NOT NULL,
    NAME VARCHAR(128) NOT NULL,
    DESCRIPTION TEXT,
    DURATION_MINUTES INTEGER NOT NULL,
    SPECIALIST_ID NUMBER(19,0) NOT NULL,
    CREATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    LAST_UPDATED TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (ID),
    FOREIGN KEY (SPECIALIST_ID) REFERENCES SPECIALIST(ID) ON DELETE CASCADE
);
----

[NOTE]
====
*Think about it:* Why might we want to cascade delete treatments when a specialist is removed? What are the implications for existing appointments?
====

=== APPOINTMENT Table

**Exercise**: Create the APPOINTMENT table with these fields:

* **ID**: Primary key
* **VERSION**: Optimistic locking
* **DATE_TIME**: Appointment start time
* **END_DATE_TIME**: Appointment end time
* **STATUS**: Appointment status (VARCHAR(32), default 'SCHEDULED')
* **CLIENT_ID**: Foreign key to CLIENT
* **TREATMENT_ID**: Foreign key to TREATMENT
* **CREATED/LAST_UPDATED**: Audit timestamps

Status values: `SCHEDULED`, `CANCELLED`, `COMPLETED`

=== Database Sequences

Create sequences for ID generation:

[source,sql]
----
CREATE SEQUENCE USER_SEQ START WITH 1 INCREMENT BY 100 NOCYCLE;
CREATE SEQUENCE CLIENT_SEQ START WITH 1 INCREMENT BY 100 NOCYCLE;
CREATE SEQUENCE SPECIALIST_SEQ START WITH 1 INCREMENT BY 100 NOCYCLE;
CREATE SEQUENCE TREATMENT_SEQ START WITH 1 INCREMENT BY 100 NOCYCLE;
CREATE SEQUENCE APPOINTMENT_SEQ START WITH 1 INCREMENT BY 100 NOCYCLE;
----

[NOTE]
====
*Think about it:* Why do we increment by 100 instead of 1? This is related to JPA's sequence allocation optimization - can you research why this improves performance?
====

=== Constraint Checks

Add a check constraint to ensure appointment end time is after start time:

[source,sql]
----
ALTER TABLE APPOINTMENT ADD CONSTRAINT CHK_APPOINTMENT_TIME 
CHECK (END_DATE_TIME > DATE_TIME);
----

=== Database Indexes

Create indexes on foreign key columns for better query performance:

[source,sql]
----
CREATE INDEX IDX_CLIENT_USER ON CLIENT(USER_ID);
CREATE INDEX IDX_SPECIALIST_USER ON SPECIALIST(USER_ID);
CREATE INDEX IDX_TREATMENT_SPECIALIST ON TREATMENT(SPECIALIST_ID);
CREATE INDEX IDX_APPOINTMENT_CLIENT ON APPOINTMENT(CLIENT_ID);
CREATE INDEX IDX_APPOINTMENT_TREATMENT ON APPOINTMENT(TREATMENT_ID);
----

[IMPORTANT]
====
Indexes on foreign keys are crucial for:
- Faster JOIN operations
- Preventing table locks during parent record updates/deletes
- Improved query performance on filtered results
====

=== Sample Data

Create `V0002__Create_mockdata.sql` with sample data:

[source,sql]
----
-- noinspection SqlResolveForFile @ table/"APPLICATION_USER"

-- Sample Users (Clients)
INSERT INTO APPLICATION_USER(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) 
VALUES (-1, 0, 'Stefan', 'Kowalski', 'passwordHash1', 'stefan.kowalski@gmail.com', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);

-- Sample Users (Specialists)  
INSERT INTO APPLICATION_USER(ID, VERSION, FIRST_NAME, LAST_NAME, PASSWORD_HASH, EMAIL, CREATED, LAST_UPDATED) 
VALUES (-5, 0, 'Anna', 'Nowak', 'passwordHash5', 'dr.nowak@clinic.com', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);

-- Continue with CLIENT, SPECIALIST, TREATMENT, and APPOINTMENT data...
----

[NOTE]
====
*Think about it:* Why do we use negative IDs for sample data? This prevents conflicts with sequence-generated positive IDs in production.
====

== Entity Implementation

=== Lombok Setup

Add Lombok dependency to the pom.xml to reduce boilerplate code:

[source,xml]
----
<dependency>
    <groupId>org.projectlombok</groupId>
    <artifactId>lombok</artifactId>
    <scope>provided</scope>
</dependency>
----

[IMPORTANT]
====
Install the Lombok plugin in your IDE for proper annotation processing and code completion.
====

=== Package Structure

Create these packages under `com.capgemini.training.appointmentbooking`:

* `dataaccess.entity` - Entity classes
* `dataaccess.converter` - JPA attribute converters  
* `common.datatype` - Enums and common types

=== BaseEntity Implementation

Notice, that attributes _version_, _lastUpdated_ and _created_ are repeated in every entity. To make the structure cleaner and avoid duplicated code, let's extract a @MappedSuperclass, that each of our entities will extend.

Create a base class in package _com.capgemini.training.appointmentbooking.dataaccess.entity_ to eliminate duplicate audit fields:

[source,java]
----
@MappedSuperclass
@Getter
public class BaseEntity {
    
    @Version
    @Setter
    private int version;

    @Column(insertable = true, updatable = false)
    private Instant created;
    
    @Column(name = "LAST_UPDATED")
    private Instant lastUpdated;
    
    @PrePersist
    public void prePersist() {
        Instant now = Instant.now();
        this.created = now;
        this.lastUpdated = now;
    }
    
    @PreUpdate
    public void preUpdate() {
        this.lastUpdated = Instant.now();
    }
}
----

[NOTE]
====
*Think about it:* Why don't we provide setters for `created` and `lastUpdated`? How do the `@PrePersist` and `@PreUpdate` annotations help maintain data integrity?
====

=== UserEntity Implementation

[source,java]
----
@Entity
@Table(name = "APPLICATION_USER")
@Getter
@Setter
public class UserEntity extends BaseEntity {
    
    @Id
    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "USER_SEQ_GEN")
    @SequenceGenerator(sequenceName = "USER_SEQ", name = "USER_SEQ_GEN", 
                       allocationSize = 100, initialValue = 1)
    private Long id;
    
    private String email;
    
    // TODO: write the rest of the code
}
----

=== Specialization Enum

Create the enum in `common.datatype` package:

[source,java]
----
public enum Specialization {
    
    DENTIST("Dentist"), 
    CARDIOLOGIST("Cardiologist"), 
    PEDIATRICIAN("Pediatrician"), 
    UROLOGIST("Urologist"), 
    NEUROLOGIST("Neurologist"), 
    ORTHOPAEDIST("Orthopaedist");
    
    private final String name;

    Specialization(String name) {
        this.name = name;
    }

    public String getName() {
        return this.name;
    }
    
    public static Specialization getByName(String name) {
        for (Specialization s : Specialization.values()) {
            if (s.getName().equals(name)) {
                return s;
            }
        }
        return null;
    }
}
----

=== Attribute Converter

Create `SpecializationConverter` in `dataaccess.converter`:

[source,java]
----
@Converter
public class SpecializationConverter implements AttributeConverter<Specialization, String> {

    @Override
    public String convertToDatabaseColumn(Specialization specialization) {
        return specialization != null ? specialization.getName() : null;
    }

    @Override
    public Specialization convertToEntityAttribute(String dbData) {
        return dbData != null ? Specialization.getByName(dbData) : null;
    }
}
----

[NOTE]
====
*Think about it:* Why use a custom converter instead of `@Enumerated`? Custom converters provide more control over database representation and are more resilient to enum reordering.
====

=== Entity Relationships

==== ClientEntity with One-to-One Relationship

[source,java]
----
@Entity
@Table(name = "CLIENT")
@Getter
@Setter
public class ClientEntity extends BaseEntity {
    
    @Id
    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "CLIENT_SEQ_GEN")
    @SequenceGenerator(sequenceName = "CLIENT_SEQ", name = "CLIENT_SEQ_GEN", 
                       allocationSize = 100, initialValue = 1)
    private Long id;
    
    @OneToOne(optional = false, fetch = FetchType.LAZY, cascade = {CascadeType.PERSIST})
    @JoinColumn(name = "USER_ID", referencedColumnName = "ID")
    private UserEntity user;
    
    @OneToMany(mappedBy = "client", fetch = FetchType.LAZY, orphanRemoval = true, 
               cascade = {CascadeType.PERSIST, CascadeType.REMOVE})
    private List<AppointmentEntity> appointments = new ArrayList<>();
}
----

==== SpecialistEntity with Converter

**Exercise**: Implement `SpecialistEntity` following the `ClientEntity` pattern, but add:
* `@Convert(converter = SpecializationConverter.class)` for the specialization field
* Bidirectional relationship with `TreatmentEntity`

=== Testing Entity Mappings

Create `EntitySmokeIT` to verify entity loading:

[source,java]
----
@DataJpaTest(bootstrapMode = BootstrapMode.LAZY)
class EntitySmokeIT {
    
    @PersistenceContext
    private EntityManager em;
    
    @Test
    void loadAllClasses() {
        // given
        Map<Class<? extends BaseEntity>, Integer> classMap = Map.of(
                UserEntity.class, 8,
                ClientEntity.class, 4,
                SpecialistEntity.class, 4,
                TreatmentEntity.class, 12,
                AppointmentEntity.class, 20
        );

        // when & then
        classMap.forEach((entityType, expectedCount) ->
                assertThat(em.createQuery("from " + entityType.getSimpleName())
                          .getResultList()).hasSize(expectedCount));
    }
}
----

[NOTE]
====
*Think about it:* Why is this test valuable even though it seems simple? It validates that all entity mappings are correct and the database schema matches our entity definitions.
====

== Repository Layer

=== Custom Repository Infrastructure

Create a base repository interface for EntityManager access:

[source,java]
----
@NoRepositoryBean
public interface BaseJpaRepository<T, ID> extends JpaRepository<T, ID> {
    EntityManager getEntityManager();
}
----

Implement the base repository:

[source,java]
----
public class BaseJpaRepositoryImpl<T, ID> extends SimpleJpaRepository<T, ID> 
        implements BaseJpaRepository<T, ID> {

    private final EntityManager entityManager;

    BaseJpaRepositoryImpl(JpaEntityInformation<T, ?> entityInformation, 
                         EntityManager entityManager) {
        super(entityInformation, entityManager);
        this.entityManager = entityManager;
    }

    @Override
    public EntityManager getEntityManager() {
        return this.entityManager;
    }
}
----

Configure Spring to use custom repositories:

[source,java]
----
@Configuration
@EnableJpaRepositories(
    repositoryBaseClass = BaseJpaRepositoryImpl.class,
    basePackages = "com.capgemini.training.appointmentbooking.dataaccess.repository")
public class DataaccessConfiguration {}
----

=== Repository Implementation

[source,java]
----
public interface AppointmentRepository extends BaseJpaRepository<AppointmentEntity, Long> {
    // Basic CRUD operations inherited from JpaRepository
}
----

=== Testing Infrastructure

Create base test classes:

[source,java]
----
public class BaseTest implements WithAssertions {
    protected Instant toInstant(String date) {
        DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");
        return LocalDateTime.parse(date, formatter)
                           .atZone(ZoneId.systemDefault())
                           .toInstant();
    }
}
----

[source,java]
----
@DataJpaTest
@Import(DataaccessConfiguration.class)
public class BaseDataJpaTest extends BaseTest {
    // Provides JPA testing context with custom repository configuration
}
----

[IMPORTANT]
====
`@DataJpaTest` provides:
- Simplified Spring context with only JPA components
- Automatic transaction rollback after each test
- H2 in-memory database configuration
- Fast test execution
====

=== Repository Testing

[source,java]
----
public class AppointmentRepositoryIT extends BaseDataJpaTest {

    @Autowired
    private AppointmentRepository appointmentRepository;

    @Test
    void testFindAll() {
        // when
        List<AppointmentEntity> result = appointmentRepository.findAll();

        // then
        assertThat(result).isNotEmpty().hasSize(20);
    }
}
----

[NOTE]
====
*Think about it:* Why do we test repository methods when they're provided by Spring Data JPA? We're testing our configuration and ensuring our entities work correctly with the framework.
====

== Advanced Querying

=== Query Method Types

Spring Data JPA offers multiple approaches for custom queries:

==== 1. Spring Query Methods

Method names are parsed to generate queries:

[source,java]
----
List<TreatmentEntity> findAllByNameContainingIgnoreCase(String name);
----

==== 2. @Query Annotation

Custom JPQL queries:

[source,java]
----
@Query("""
        SELECT a FROM AppointmentEntity a
        JOIN a.treatment t
        WHERE t.specialist.id = :specialistId
        AND a.dateTime < :date
        ORDER BY a.dateTime DESC
        """)
List<AppointmentEntity> findAppointmentsBySpecialistIdBeforeDate(
    @Param("specialistId") Long specialistId, 
    @Param("date") Instant date);
----

==== 3. Named Queries

Defined in entity classes:

[source,java]
----
@NamedQuery(name = "SpecialistEntity.findBySpecialization",
    query = "select s from SpecialistEntity s where specialization = :specialization")
----

==== 4. Criteria API

Type-safe programmatic queries:

[source,java]
----
default List<AppointmentEntity> findByCriteria(AppointmentCriteria criteria) {
    CriteriaBuilder cb = getEntityManager().getCriteriaBuilder();
    CriteriaQuery<AppointmentEntity> cq = cb.createQuery(AppointmentEntity.class);
    Root<AppointmentEntity> root = cq.from(AppointmentEntity.class);
    
    List<Predicate> predicates = new ArrayList<>();
    
    if (criteria.status() != null) {
        predicates.add(cb.equal(root.get("status"), criteria.status()));
    }
    
    cq.where(predicates.toArray(new Predicate[0]));
    return getEntityManager().createQuery(cq).getResultList();
}
----

==== 5. QueryDSL

Fluent, type-safe query API:

[source,java]
----
default List<ClientEntity> findByName(String firstName, String lastName) {
    JPAQueryFactory queryFactory = new JPAQueryFactory(getEntityManager());
    
    QClientEntity client = QClientEntity.clientEntity;
    QUserEntity user = QUserEntity.userEntity;
    
    return queryFactory
            .selectFrom(client)
            .leftJoin(client.user, user)
            .where(user.firstName.eq(firstName)
                    .and(user.lastName.eq(lastName)))
            .fetch();
}
----

[NOTE]
====
*Think about it:* When would you choose each query method? Consider factors like complexity, type safety, maintainability, and team expertise.
====

== Exercises

=== Exercise 1: Basic Queries

Implement and test these queries:

1. **Find treatments by partial name** (case-insensitive)
   - Use Spring Query Methods
   - Method signature: `List<TreatmentEntity> findAllByNameContainingIgnoreCase(String name)`

2. **Find past appointments for a specialist**
   - Use `@Query` annotation with JOIN
   - Include only appointments before current date
   - Exclude cancelled appointments

=== Exercise 2: Advanced Queries

Implement these more complex queries:

1. **Find appointments by time period and status** - Spring Query Methods
2. **Find conflicting appointments** - `@Query` (exclude CANCELLED status)
3. **Find treatment by name** - Named Query
4. **Find treatments by name and specialization** - QueryDSL
5. **Find appointment history** - Criteria API

[IMPORTANT]
====
Remember to:
- Write comprehensive tests for each query
- Handle edge cases (null parameters, empty results)
- Consider performance implications
- Document complex query logic
====

== Troubleshooting Common Issues

=== IllegalStateException: Failed to load ApplicationContext

**Cause**: Query compilation errors detected at runtime

**Solution**: 
- Check JPQL syntax carefully
- Verify entity and field names
- Ensure proper parameter binding

=== LazyInitializationException

**Cause**: Accessing lazy-loaded associations outside transaction context

**Solution**:
- Use `@Transactional` on service methods
- Fetch required associations explicitly
- Consider fetch strategies carefully

[WARNING]
====
JPA queries are validated at runtime, not compile-time. Always test your custom queries thoroughly to catch errors early.
====

== Best Practices Summary

1. **Entity Design**:
   - Use `@MappedSuperclass` for common fields
   - Implement proper equals/hashCode for entities
   - Choose appropriate fetch strategies

2. **Repository Design**:
   - Extend custom base repository for EntityManager access
   - Use appropriate query method for each use case
   - Write comprehensive integration tests

3. **Performance Considerations**:
   - Create indexes on frequently queried columns
   - Use lazy loading appropriately
   - Consider query complexity and N+1 problems

4. **Testing**:
   - Use `@DataJpaTest` for repository tests
   - Test both positive and negative scenarios
   - Verify query performance with realistic data volumes

[NOTE]
====
*Think about it:* How does proper data access layer design contribute to overall application maintainability and performance? Consider the impact on testing, debugging, and future feature development.
====

== Navigation

[cols="1,1"]
|===
| link:appointment-booking-system-specification.asciidoc[← Previous: System Specification] | link:appointment-booking-service-business-logic-layer.asciidoc[Next: Business Logic Layer →]
|===